{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74f5f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import UnstructuredHTMLLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d3d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and Parse Sitemaps to Create List of all website's pages\n",
    "import usp\n",
    "from usp.tree import sitemap_tree_for_homepage\n",
    "\n",
    "def getPagesFromSitemap(fullDomain):\n",
    "    listPagesRaw = []\n",
    "    tree = sitemap_tree_for_homepage(fullDomain)\n",
    "    for page in tree.all_pages():\n",
    "        listPagesRaw.append(page.url)\n",
    "    return listPagesRaw\n",
    "\n",
    "# Go through List Pages Raw output a list of unique pages links\n",
    "def getListUniquePages(listPagesRaw):\n",
    "    listPages = []\n",
    "    for page in listPagesRaw:\n",
    "        if page in listPages: \n",
    "            pass\n",
    "        else: \n",
    "            listPages.append(page)\n",
    "    return listPages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33306912",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"input key here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804d6098",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = 0\n",
    "while (user_input!=\"1\") and (user_input!=\"2\"):\n",
    "    user_input = input('Please enter \"1\" in case you want to upload the files or \"2\" if you want to fetch the files from the url'\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9605183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if user_input==\"1\":\n",
    "    j=0\n",
    "    \n",
    "    lan_input = ''\n",
    "    while (lan_input!=\"html\") and (lan_input!=\"pdf\"):\n",
    "        lan_input = input('Please enter \"html\" in case you want to upload the html files or \"pdf\" if you want to upload PDF files'\"\\n\")\n",
    "    \n",
    "    if lan_input=='pdf':\n",
    "        path_input = \"enter your path\"\n",
    "        documents = []\n",
    "        for file in os.listdir(path_input):\n",
    "            pdf_path = path_input + file\n",
    "            loader = PyPDFLoader(pdf_path)\n",
    "            documents.extend(loader.load())\n",
    "            j = j+1\n",
    "            print(j,' of ', len(os.listdir(path_input)), ' PDFs processed')\n",
    "    \n",
    "    if lan_input=='html':\n",
    "        path_input = \"enter your path\"\n",
    "        for file in os.listdir(path_input):\n",
    "            html_path = path_input + file\n",
    "            loader = UnstructuredHTMLLoader(html_path)\n",
    "            documents.extend(loader.load())\n",
    "            j = j+1\n",
    "            print(j,' of ', len(os.listdir(path_input)), ' html files processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eac4c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "if user_input==\"2\":\n",
    "    url_input = input('Please enter the url that will be crawled: ')\n",
    "    test = getPagesFromSitemap(url_input)\n",
    "    urls = getListUniquePages(test)\n",
    "    #create a list containing the path names that the files will be created in\n",
    "    path = []\n",
    "    path_input = input('Please enter the path were the files will be stored: ')\n",
    "    for i in range(len(urls)):\n",
    "        path.append(path_input + str(i) + '.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264a2046",
   "metadata": {},
   "outputs": [],
   "source": [
    " #save the html code to htmls files\n",
    "import requests\n",
    "if user_input==\"2\":\n",
    "    i = 0\n",
    "    for url in urls:\n",
    "        text_file = open(path[i], \"w\", encoding=\"utf-8\")\n",
    "        text_file.write(requests.get(url = url).text)\n",
    "        text_file.close()\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d22d88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if user_input==\"2\":\n",
    "    documents = []\n",
    "    for i in range(len(urls)):\n",
    "        loader = UnstructuredHTMLLoader(f'enter your path here'{i}.html')\n",
    "        documents.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513e3ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "documents = text_splitter.split_documents(documents)\n",
    "for i in range(len(documents)):\n",
    "    documents[i].page_content = documents[i].page_content.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630a3077",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = FAISS.from_documents(documents, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7d970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an AI assistant for answering questions about the university of limassol website.\n",
    "You are given the following extracted parts of a long document and a question. Provide a conversational answer.\n",
    "If you don't know the answer, just say \"Hmm, I'm not sure.\" Don't try to make up an answer.\n",
    "Question: {question}\n",
    "=========\n",
    "{context}\n",
    "=========\n",
    "Answer in Markdown:\"\"\"\n",
    "QA_PROMPT = PromptTemplate(template=template, input_variables=[\n",
    "                           \"question\", \"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b08833",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_qa = ConversationalRetrievalChain.from_llm(\n",
    "    ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\"),\n",
    "    vectordb.as_retriever(search_kwargs={'k': 5}),\n",
    "    return_source_documents=True,\n",
    "    verbose=False,\n",
    "    max_tokens_limit=2000,\n",
    "    combine_docs_chain_kwargs={\"prompt\": QA_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e04f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow = \"\\033[0;33m\"\n",
    "green = \"\\033[0;32m\"\n",
    "white = \"\\033[0;39m\"\n",
    "\n",
    "chat_history = []\n",
    "print(f\"{yellow}---------------------------------------------------------------------------------\")\n",
    "print('Welcome to the AI Chabot. Ask me questions about your documents')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "while True:\n",
    "    query = input(f\"{green}Prompt: \")\n",
    "    if query == \"exit\" or query == \"quit\" or query == \"q\" or query == \"f\":\n",
    "        print('Exiting')\n",
    "        sys.exit()\n",
    "    if query == '':\n",
    "        continue\n",
    "    result = pdf_qa(\n",
    "        {\"question\": query, \"chat_history\": chat_history})\n",
    "    print(f\"{white}Answer: \" + result[\"answer\"])\n",
    "    chat_history.append((query, result[\"answer\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
